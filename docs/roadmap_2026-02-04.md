# AIPipeline Tool — Master Roadmap

**Date:** 2026-02-04
**Version:** 2.0
**Author:** Dongseo University Virtual Convergence Technology Research Institute & Red Cat Gang Co., Ltd.

---

## Vision Statement

> **시나리오 텍스트 하나를 입력하면, AI가 캐릭터·샷·배경을 자동 분리하고,
> 웹 브라우저 하나에서 프리프로덕션부터 최종 AI 렌더링까지
> 전체 영상 제작 파이프라인을 관리할 수 있는 시스템.**

이 도구는 단순한 렌더팜이 아니다.
AI 영상 제작의 **모든 의사결정과 반복작업**을 웹에서 처리하고,
사람은 **창작 판단에만 집중**할 수 있게 하는 것이 목표다.

---

## Core Design Principles

1. **웹에서 전부 된다** — 설치 없이 브라우저 하나로 전체 파이프라인 운용
2. **사람이 매 단계 컨펌한다** — AI가 자동으로 만들되, 핵심 결정은 사람이 한다
3. **외부 툴과 자유롭게 왔다갔다** — 엑셀 export/import, DCC 툴 연동, EDL 출력
4. **첫 이미지가 모든 것의 기준** — i2v 모델 품질이 첫 이미지에 의존하므로, 프리프로덕션에서 이미지 퀄리티를 확보하는 것이 최우선
5. **네이밍 컨벤션과 폴더 구조는 자동** — 컨펌 순간 프로덕션 표준 폴더가 생성된다

---

## Pipeline Overview

```
┌─────────────────────────────────────────────────────────────────────┐
│                        FULL PIPELINE FLOW                          │
│                                                                     │
│  [시나리오 텍스트]                                                   │
│       │                                                             │
│       ▼                                                             │
│  ┌─────────────┐    ┌──────────────┐    ┌────────────────┐         │
│  │  LLM 분석   │───▶│  샷리스트     │───▶│  데이터 구조    │         │
│  │  캐릭터분리  │    │  배경분리     │    │  자동 생성     │         │
│  │  배경분리    │    │  캐릭터시트   │    │  (네이밍 컨벤션)│         │
│  └─────────────┘    └──────────────┘    └────────────────┘         │
│                            │                     │                  │
│                     ┌──────┴──────┐              │                  │
│                     ▼             ▼              ▼                  │
│              [웹 편집]     [엑셀 Export]   [폴더 구조 생성]          │
│              [Airtable]    [외부 편집]     SHT-00001/               │
│                     │      [Import]       SHT-00002/               │
│                     ▼             │       ...                       │
│                     └──────┬──────┘                                 │
│                            ▼                                        │
│  ┌──────────────────────────────────────────┐                      │
│  │         PRE-PRODUCTION                    │                      │
│  │  t2i / i2i 첫 이미지 생성                 │                      │
│  │  QwenImageEdit 재편집                     │                      │
│  │  카메라·구도·캐릭터 위치 확정              │                      │
│  │  (↔ DCC 툴 왕복 가능)                     │                      │
│  └──────────────────┬───────────────────────┘                      │
│                     ▼                                               │
│  ┌──────────────────────────────────────────┐                      │
│  │         PREVIZ / PROXY EDIT               │                      │
│  │  첫 이미지 + 샷 길이 → 프록시 편집본      │                      │
│  │  웹 타임라인에서 1차 편집                  │                      │
│  │  샷 순서 변경, 길이 조절, 삭제/추가        │                      │
│  └──────────────────┬───────────────────────┘                      │
│                     ▼                                               │
│  ┌──────────────────────────────────────────┐                      │
│  │         MAIN PRODUCTION                   │                      │
│  │  DCC 툴 연동 (3D 레이아웃)                │                      │
│  │  모션·카메라 → 플레이블라스트              │                      │
│  │  웹에서 확인 → 컨펌                       │                      │
│  │  최종 AI 렌더 실행                        │                      │
│  └──────────────────┬───────────────────────┘                      │
│                     ▼                                               │
│  ┌──────────────────────────────────────────┐                      │
│  │         POST-PRODUCTION                   │                      │
│  │  프레임 보간 / 업스케일                    │                      │
│  │  최종 편집 → EDL/XML Export                │                      │
│  │  DaVinci / Premiere 연동                  │                      │
│  └──────────────────────────────────────────┘                      │
└─────────────────────────────────────────────────────────────────────┘
```

---

## Production Phases (상세)

### Phase 0: Foundation — 기존 버그 수정 및 안정화
> **현재 코드의 런타임 에러와 구조적 문제를 먼저 잡는다.**

| # | Task | Detail | Priority |
|---|------|--------|----------|
| 0.1 | cinematics.py 런타임 버그 수정 | 미정의 변수 참조 (`routers/cinematics.py:17`) | CRITICAL |
| 0.2 | Character 모델 필드 추가 | `use_lora`, `default_clothing` 필드 누락 → prompt_engine과 불일치 | CRITICAL |
| 0.3 | shots.py export 함수 수정 | 미정의 `subjects` 변수 참조 (`routers/shots.py:92`) | CRITICAL |
| 0.4 | ShotTable 중복 컬럼 제거 | `ShotTable.jsx:305-308` Subjects, Env 컬럼 이중 정의 | HIGH |
| 0.5 | 환경변수 분리 | 하드코딩된 URL을 `.env`로 분리 (Master, ComfyUI, Frontend) | HIGH |
| 0.6 | 에러 처리 개선 | `except Exception: pass` → 구체적 예외 + 로깅 | HIGH |
| 0.7 | 구조화된 로깅 | `print()` → Python `logging` 모듈 전환 | HIGH |
| 0.8 | GPU 감지 실패 처리 | 가짜 RTX 4090 데이터 대신 에러 상태 반환 | MEDIUM |

**Milestone:** 서버가 에러 없이 기동되고, 기본 CRUD가 정상 동작한다.

---

### Phase 1: Scenario Analysis — LLM 시나리오 자동 분석
> **시나리오 텍스트를 넣으면 캐릭터·샷리스트·배경이 자동 분리된다.**

#### 의도
영상 제작의 첫 단계. 감독이 시나리오나 콘셉트 텍스트를 넣으면
LLM이 이를 분석하여 프로덕션에 필요한 기본 데이터를 자동 생성한다.
사람이 처음부터 하나하나 입력할 필요 없이, AI가 초안을 잡아주고 사람이 수정한다.

#### Tasks

| # | Task | Detail |
|---|------|--------|
| 1.1 | LLM 시나리오 파서 서비스 | 시나리오 텍스트 → 구조화된 JSON 출력 (캐릭터, 샷, 배경, 감정, 시간대) |
| 1.2 | 캐릭터 자동 추출 | 등장인물 이름, 외형 묘사, 의상, 관계를 Character 모델로 자동 생성 |
| 1.3 | 샷리스트 자동 생성 | 장면별 샷 분해: 액션, 카메라 앵글 추천, 예상 길이 |
| 1.4 | 배경/환경 자동 분리 | 장소, 시간대, 날씨, 분위기를 Environment 데이터로 분리 |
| 1.5 | 시나리오 입력 UI | 텍스트 에어리어 + 분석 결과 프리뷰 + "적용" 버튼 |
| 1.6 | 분석 결과 편집 UI | 자동 생성된 캐릭터/샷/배경을 테이블에서 바로 수정 가능 |
| 1.7 | 소형 LLM 지원 | Ollama (Mistral, Llama 등) 로컬 실행 옵션. OpenAI API 의존 제거 |
| 1.8 | 프롬프트 템플릿 시스템 | 시나리오 분석용 시스템 프롬프트 버전 관리 |

**Input:** 시나리오 텍스트 (자유 형식)
**Output:** Characters[], Shots[], Environments[] — 편집 가능한 상태로 테이블에 로드

**LLM 출력 스키마 (예시):**
```json
{
  "characters": [
    {
      "name": "리나",
      "description": "20대 중반 여성, 짧은 검은 머리, 날카로운 눈매",
      "clothing": ["검은 가죽 재킷", "회색 터틀넥"],
      "role": "주인공"
    }
  ],
  "shots": [
    {
      "scene": 1,
      "shot_number": 1,
      "description": "리나가 빗속에서 골목을 걸어간다",
      "action": "walking slowly through rain",
      "suggested_camera": "tracking shot, low angle",
      "suggested_duration": 4.0,
      "environment_ref": "ENV-001"
    }
  ],
  "environments": [
    {
      "id": "ENV-001",
      "location": "좁은 골목길",
      "time_of_day": "밤",
      "weather": "비",
      "mood": "긴장감, 고독"
    }
  ]
}
```

**Milestone:** 시나리오 텍스트를 붙여넣으면 캐릭터/샷/배경 테이블이 자동으로 채워진다.

---

### Phase 2: Shot Management — Airtable 스타일 샷리스트 편집
> **웹에서 직접 편집하거나, 엑셀로 뽑아서 외부에서 편집하고 다시 가져온다.**

#### 의도
샷리스트는 영상 제작의 핵심 문서다.
웹에서 바로 편집할 수 있어야 하고, 동시에 엑셀로 export해서
익숙한 도구로 작업한 후 다시 import할 수 있어야 한다.
형식별(샷리스트, 배경 프롬프트, 캐릭터 시트)로 나눠서 뽑을 수 있어야
각 담당자가 자기 영역만 편집할 수 있다.

#### Tasks

| # | Task | Detail |
|---|------|--------|
| 2.1 | ShotTable 고도화 | 인라인 편집, 드래그 정렬, 멀티셀 선택, 복사/붙여넣기 |
| 2.2 | 컬럼 커스터마이징 | 사용자가 컬럼 표시/숨김, 순서 변경, 컬럼 너비 조절 |
| 2.3 | 필터/정렬/그룹핑 | Scene별, Status별, Character별 그룹핑. 다중 조건 필터 |
| 2.4 | 엑셀 Export (형식별) | 샷리스트 전체, 배경 프롬프트만, 캐릭터 시트만, 기술 스펙만 — 각각 분리 export |
| 2.5 | 엑셀 Import + 머지 | 외부 편집된 엑셀을 다시 import. 기존 데이터와 diff 표시 후 선택적 머지 |
| 2.6 | CSV/JSON Export | 범용 포맷 지원 |
| 2.7 | 샷 상태 워크플로우 | `draft → ready → generating → review → approved → final` 상태 전이 관리 |
| 2.8 | 썸네일 컬럼 | 생성된 이미지 썸네일을 테이블 행에 표시 |
| 2.9 | Undo/Redo | 편집 히스토리 (최소 50스텝) |
| 2.10 | 실시간 자동저장 | 편집 즉시 서버 저장 + 충돌 감지 |
| 2.11 | 캐릭터 바이블 고도화 | LoRA 경로, 트리거 워드, 의상 옵션, 레퍼런스 시트 관리 |
| 2.12 | 시네마틱 프리셋 편집 | 카메라/렌즈/필름/조명 프리셋 CRUD + 프리셋 복제 |
| 2.13 | ID 생성 서버사이드화 | `Date.now()` 기반 → UUID 또는 서버 시퀀스 |

**Milestone:** 샷리스트를 웹에서 자유롭게 편집하고, 엑셀로 내보내고, 수정 후 다시 가져올 수 있다.

---

### Phase 3: Data Structure Generation — 컨펌 → 자동 폴더 생성
> **샷리스트가 컨펌되면 네이밍 컨벤션에 맞춘 프로덕션 폴더가 자동 생성된다.**

#### 의도
샷리스트가 확정되면 그 순간부터 "프로덕션 모드"로 전환된다.
각 샷별로 표준 폴더 구조가 생성되고, 이후 생성되는 모든 에셋은
이 구조 안에 자동으로 정리된다. 네이밍 컨벤션을 사람이 일일이 맞출 필요가 없다.

#### Tasks

| # | Task | Detail |
|---|------|--------|
| 3.1 | 네이밍 컨벤션 엔진 | 프로젝트명, 씬번호, 샷번호, 버전, 타입을 조합하는 규칙 엔진 |
| 3.2 | 폴더 구조 자동 생성 | 컨펌 버튼 → 전체 프로덕션 폴더 트리 일괄 생성 |
| 3.3 | 프로젝트 루트 구조 | `PRJ_NAME/scenes/SCN_001/shots/SHT_001/{previz,layout,render,comp,final}` |
| 3.4 | 버전 관리 디렉토리 | `SHT_001/previz/v001/`, `v002/` ... 버전별 하위 폴더 |
| 3.5 | 메타데이터 JSON 생성 | 각 샷 폴더에 `shot_meta.json` 자동 배치 (프롬프트, 설정, 히스토리) |
| 3.6 | 공유 스토리지 연동 | 생성된 구조를 NAS/네트워크 드라이브에 미러링 |
| 3.7 | 컨펌/락 시스템 | 컨펌된 샷은 구조 변경 불가. 언락은 명시적 동작 필요 |
| 3.8 | 증분 업데이트 | 샷 추가/삭제시 기존 구조를 파괴하지 않고 증분 반영 |

**폴더 구조 예시:**
```
projects/
└── MyProject_2026/
    ├── project_config.json
    ├── assets/
    │   ├── characters/
    │   │   ├── CHR_리나/
    │   │   │   ├── lora/
    │   │   │   ├── reference/
    │   │   │   └── character_meta.json
    │   │   └── CHR_민수/
    │   └── environments/
    │       ├── ENV_골목길/
    │       └── ENV_옥상/
    ├── scenes/
    │   ├── SCN_001/
    │   │   ├── shots/
    │   │   │   ├── SHT_001/
    │   │   │   │   ├── previz/        ← t2i/i2i 이미지
    │   │   │   │   │   ├── v001/
    │   │   │   │   │   └── v002/
    │   │   │   │   ├── layout/        ← DCC 3D 레이아웃
    │   │   │   │   ├── playblast/     ← 플레이블라스트 영상
    │   │   │   │   ├── render/        ← AI 최종 렌더
    │   │   │   │   ├── comp/          ← 합성
    │   │   │   │   ├── final/         ← 최종 출력
    │   │   │   │   └── shot_meta.json
    │   │   │   └── SHT_002/
    │   │   └── scene_meta.json
    │   └── SCN_002/
    ├── edit/
    │   ├── proxy/                     ← 프록시 편집본
    │   ├── edl/                       ← EDL/XML 출력
    │   └── timeline_state.json
    └── export/
        ├── dailies/
        └── final/
```

**Milestone:** "컨펌" 버튼을 누르면 위 구조가 자동 생성되고, 이후 모든 에셋이 올바른 위치에 저장된다.

---

### Phase 4: Pre-Production Image Generation — 첫 이미지 생성 및 편집
> **각 샷의 첫 이미지를 생성하고, 구도·캐릭터·카메라를 확정한다.
> 이 이미지가 이후 모든 작업(i2v, 3D 레이아웃)의 기준이 된다.**

#### 의도
대부분의 i2v 모델(WAN-Animate, LTX-2, SVI 등)은 첫 이미지 품질에
최종 영상 품질이 크게 좌우된다. 따라서 프리프로덕션 단계에서
첫 이미지의 구도, 캐릭터 위치, 카메라 앵글을 완벽하게 잡는 것이 핵심이다.

t2i로 초안을 만들고 → i2i로 디테일을 잡고 → QwenImageEdit 같은
이미지 편집 AI로 부분 수정하는 반복 루프를 웹에서 처리한다.

#### Tasks

| # | Task | Detail |
|---|------|--------|
| 4.1 | t2i 배치 생성 | 샷리스트 전체 또는 선택된 샷들에 대해 일괄 이미지 생성 (FLUX) |
| 4.2 | 프롬프트 엔진 고도화 | 캐릭터 LoRA + 환경 + 시네마틱 스펙 → 최종 프롬프트 자동 조립 |
| 4.3 | LoRA 동적 로딩 | 캐릭터별 LoRA를 워크플로우에 동적 주입 (강도 조절 가능) |
| 4.4 | i2i 리파인 루프 | 생성된 이미지를 기반으로 i2i 재생성 (강도, 디노이즈 조절) |
| 4.5 | 이미지 편집 AI 연동 | QwenImageEdit, InstructPix2Pix 등 — 부분 수정 (배경 변경, 포즈 수정, 오브젝트 추가/제거) |
| 4.6 | 인페인팅/아웃페인팅 | 마스크 기반 부분 재생성, 프레임 확장 |
| 4.7 | 이미지 비교 뷰어 | Before/After 슬라이더, 버전 갤러리, A/B 비교 |
| 4.8 | 샷별 이미지 버전 관리 | v001, v002... 자동 버전닝. 모든 시도를 보존 |
| 4.9 | 컨트롤넷 지원 | 포즈(OpenPose), 깊이(Depth), 엣지(Canny) 조건 이미지 입력 |
| 4.10 | 레퍼런스 이미지 업로드 | 참고 이미지를 드래그앤드롭으로 샷에 연결 |
| 4.11 | 승인/반려 워크플로우 | 이미지 리뷰 → 승인(다음 단계로) / 반려(재생성) / 코멘트 |
| 4.12 | 워커 작업 완료 감지 | ComfyUI history API 폴링, 진행률 실시간 표시 |
| 4.13 | VRAM 기반 작업 분배 | 워크플로우별 VRAM 요구량 ↔ 워커 가용 메모리 매칭 |

**Milestone:** 모든 샷에 대해 품질 확보된 첫 이미지가 존재하고, 승인 상태이다.

---

### Phase 5: Previz & Proxy Edit — 프록시 편집본 생성 및 1차 편집
> **첫 이미지들을 이어붙여 프록시 편집본을 만들고, 웹에서 1차 편집한다.**

#### 의도
프리비즈 이미지가 확보되면, 각 이미지별로 "이 샷은 3초, 이 샷은 5초"
식으로 길이를 지정해서 이어붙인 프록시 영상을 만든다.
이걸 타임라인에서 보면서 순서를 바꾸고, 길이를 줄이고 늘이고,
삭제하고 추가하는 1차 편집을 웹에서 한다.

아직 영상이 아니라 이미지 기반이지만, 전체 흐름과 페이싱을 잡는 단계.

#### Tasks

| # | Task | Detail |
|---|------|--------|
| 5.1 | 프록시 영상 생성기 | 승인된 첫 이미지 + 샷 길이(초) → 이미지 시퀀스 영상 (ffmpeg) |
| 5.2 | 타임라인 UI 재설계 | 드래그 리사이즈(길이 조절), 드래그 리오더(순서 변경), 스냅 |
| 5.3 | 플레이백 엔진 | 웹 비디오 플레이어. 타임코드 표시, 프레임 단위 이동 |
| 5.4 | 트랙 시스템 | Video Track, Audio Track (참고용), Marker Track |
| 5.5 | 샷 길이 조절 | 타임라인에서 드래그로 프레임/초 단위 조절 → 샷 데이터 자동 동기화 |
| 5.6 | 샷 순서 변경 | 드래그로 순서 교체 → 샷리스트 순번 자동 업데이트 |
| 5.7 | 샷 삭제/추가/분할 | 타임라인에서 직접 샷 CRUD. 분할시 새 샷 데이터 자동 생성 |
| 5.8 | 마커/코멘트 | 특정 시점에 마커를 찍고 코멘트 작성 (리뷰용) |
| 5.9 | 프록시 재생성 | 편집 변경 후 "미리보기 갱신" → 변경된 구간만 재생성 |
| 5.10 | EDL/XML Export | CMX3600 EDL, FCP XML 출력 → Premiere / DaVinci Resolve |
| 5.11 | 프레임레이트 설정 | 프로젝트별 FPS (24, 25, 30, 60) 설정 |
| 5.12 | 키보드 단축키 | J/K/L 재생 제어, I/O 마크 인아웃, 방향키 프레임 이동 |

**Milestone:** 첫 이미지 기반 프록시 편집본이 웹에서 재생되고, 순서/길이 편집 후 EDL로 내보낼 수 있다.

---

### Phase 6: Main Production — DCC 툴 연동 및 AI 렌더
> **DCC 툴과 왔다갔다 하면서 3D 레이아웃을 잡고, 최종 AI 렌더를 실행한다.**

#### 의도
프리비즈가 끝나면 메인 프로덕션에 들어간다.
첫 이미지를 기반으로 DCC 툴(Blender, Maya, Houdini 등)에서
3D 레이아웃을 만들고, 카메라 모션과 캐릭터 모션을 잡는다.

DCC에서 플레이블라스트가 나오면 이걸 다시 웹으로 가져와서
타임라인에서 확인하고 컨펌한다. 컨펌되면 최종 AI 렌더를 돌린다.

이 단계에서는 웹과 DCC 사이의 **양방향 데이터 교환**이 핵심이다.

#### Tasks

| # | Task | Detail |
|---|------|--------|
| 6.1 | DCC 브릿지 프로토콜 | Blender/Maya/Houdini ↔ 파이프라인 데이터 교환 포맷 정의 |
| 6.2 | Blender 애드온 | 샷 메타데이터 가져오기, 카메라 셋업 자동화, 플레이블라스트 업로드 |
| 6.3 | 첫 이미지 → 3D 레이아웃 가이드 | 첫 이미지를 카메라 배경으로 배치하여 3D 구도 매칭 가이드 |
| 6.4 | 플레이블라스트 업로드 | DCC에서 렌더한 플레이블라스트를 웹에 업로드 → 타임라인 교체 |
| 6.5 | 플레이블라스트 리뷰 UI | 웹에서 재생, 코멘트, 승인/반려 |
| 6.6 | 모션 데이터 교환 | 카메라 모션 (FBX/Alembic), 캐릭터 모션 데이터 import/export |
| 6.7 | AI 렌더 실행 | 컨펌된 샷 → i2v 워크플로우 실행 (WAN-Animate, LTX-2, SVI 등) |
| 6.8 | 멀티 워크플로우 지원 | 샷별로 다른 워크플로우 선택 가능 (액션샷=WAN, 정적=FLUX+SVI 등) |
| 6.9 | 렌더 큐 매니저 | 우선순위 큐, 의존성 관리 (선행 샷 완료 후 다음 샷), 재시도 로직 |
| 6.10 | 렌더 진행률 실시간 표시 | WebSocket으로 워커 → Master → Frontend 실시간 진행률 |
| 6.11 | 렌더 결과 자동 배치 | 완성된 영상을 `SHT_001/render/v001/` 에 자동 저장 |
| 6.12 | A/B 렌더 비교 | 동일 샷의 서로 다른 워크플로우/설정 결과를 나란히 비교 |
| 6.13 | 렌더 설정 프리셋 | 워크플로우 + 파라미터 조합을 프리셋으로 저장/공유 |

**Milestone:** DCC 툴에서 작업한 플레이블라스트를 웹에서 확인하고, 컨펌된 샷의 AI 렌더가 자동 실행된다.

---

### Phase 7: Post-Production & Publishing — 후처리 및 최종 출력
> **프레임 보간, 업스케일, 최종 편집, 포맷 변환을 처리한다.**

#### Tasks

| # | Task | Detail |
|---|------|--------|
| 7.1 | 프레임 보간 | RIFE/FILM 기반 프레임 보간 (24fps → 60fps 등) |
| 7.2 | 업스케일 | 저해상도 렌더 → 고해상도 업스케일 (Real-ESRGAN 등) |
| 7.3 | 샷 조합 | 개별 렌더 영상을 타임라인 순서대로 결합 |
| 7.4 | 오디오 트랙 | 임시 음악/효과음 배치 (최종 음향은 외부 처리) |
| 7.5 | 최종 Export | ProRes, H.264, H.265 등 포맷별 출력 |
| 7.6 | EDL/XML 최종 출력 | DaVinci Resolve / Premiere Pro용 편집 데이터 |
| 7.7 | 프로젝트 아카이브 | 전체 프로젝트를 ZIP 패키징 (설정 + 에셋 + 렌더 + 편집 데이터) |
| 7.8 | Dailies 자동 생성 | 당일 작업 결과를 자동 컴파일한 데일리 영상 |

**Milestone:** 완성된 AI 영상이 프로덕션 표준 포맷으로 출력되고, NLE 소프트웨어로 넘길 수 있다.

---

### Phase 8: Infrastructure — 인프라 및 안정성
> **프로덕션 사용을 위한 인프라 강화.**

#### Tasks

| # | Task | Detail |
|---|------|--------|
| 8.1 | DB 마이그레이션 | JSON → SQLite (즉시) → PostgreSQL (스케일링시) |
| 8.2 | DB 스키마 마이그레이션 | Alembic 기반 스키마 버전 관리 |
| 8.3 | 인증/권한 | JWT 토큰 기반 인증. 역할별 접근 제어 (Admin, Director, Artist) |
| 8.4 | WebSocket 안정화 | 재연결 로직, 하트비트 타임아웃, 연결 상태 모니터링 |
| 8.5 | 워커 장애 복구 | 워커 다운시 작업 자동 재할당, 체크포인트 복구 |
| 8.6 | 백업 시스템 | 프로젝트 데이터 자동 백업 (일일/주간) |
| 8.7 | 모니터링 대시보드 | 전체 팜 GPU 사용률, 작업 처리량, 에러율 실시간 모니터링 |
| 8.8 | API 문서 자동 생성 | FastAPI OpenAPI 스펙 + Swagger UI |
| 8.9 | 테스트 코드 | 핵심 서비스 unit test, API integration test |
| 8.10 | Docker 컨테이너화 | Master/Worker Docker 이미지. docker-compose로 원클릭 배포 |
| 8.11 | CORS 정책 강화 | 허용 origin 명시, 불필요한 메서드 차단 |

---

## Development Order (개발 순서)

> **파이프라인 순서 ≠ 개발 순서.**
> LLM 시나리오 분석(Phase 1)은 파이프라인의 첫 단계이지만,
> 없어도 수동 입력으로 대체 가능하다.
> 반면 샷리스트 편집(Phase 2)과 폴더 구조(Phase 3)가 없으면
> 아무 데이터도 입력할 수 없고, 생성된 에셋이 갈 곳도 없다.
>
> **"지금 당장 쓸 수 있는 도구"부터 만든다.**

```
실제 개발 순서:

Phase 0: 버그 수정/안정화          ← 지금 바로. 서버가 에러 없이 돌아야 한다
  │
  ▼
Phase 2: 샷리스트 편집             ← 최우선. 데이터 입력/편집이 모든 것의 시작
Phase 3: 폴더 구조 자동 생성       ← 2와 세트. 컨펌하면 폴더가 생겨야 한다
  │
  ▼
Phase 4: 이미지 생성/편집          ← 핵심 작업 루프. 가장 많이 반복하는 구간
  │
  ▼
Phase 5: 프록시 편집/타임라인       ← 이미지 나오면 바로 이어붙여서 흐름을 봐야 함
  │
  ▼
Phase 6: AI 렌더 + DCC 연동       ← 메인 프로덕션
Phase 7: 후처리/출력               ← 렌더 나오면 바로 필요
  │
  ▼
Phase 1: LLM 시나리오 분석         ← 편의 기능. 수동 입력으로 대체 가능하므로 후순위
  │
  ║
  ║  Phase 8: 인프라 강화           ← 전 구간 병행. 필요할 때마다 점진적으로
  ║
```

### 개발 순서 근거

| 순서 | Phase | 왜 이 순서인가 |
|------|-------|---------------|
| 1st | **0 — 버그 수정** | 현재 코드에 런타임 에러가 있다. 서버가 정상 기동해야 다음 작업이 가능 |
| 2nd | **2 — 샷리스트 편집** | 샷리스트가 **모든 데이터의 원본**이다. 입력/편집/export가 안 되면 파이프라인 자체가 시작 불가 |
| 3rd | **3 — 폴더 구조 생성** | 샷리스트 컨펌 → 프로덕션 폴더가 자동 생성되어야 이후 생성물이 갈 곳이 있다. Phase 2와 거의 붙어서 개발 |
| 4th | **4 — 이미지 생성** | 첫 이미지가 전체 품질을 결정한다. **가장 많이 반복**하는 작업이므로 빨리 안정화해야 함 |
| 5th | **5 — 프록시 편집** | 이미지가 나오면 바로 이어붙여서 전체 흐름과 페이싱을 확인해야 편집 판단이 된다 |
| 6th | **6 — DCC + AI 렌더** | 여기까지 오면 실제 작품 제작이 가능. DCC 연동은 복잡하지만 핵심 가치 |
| 7th | **7 — 후처리/출력** | 렌더 결과물의 마무리. 보간, 업스케일, 포맷 변환 |
| 8th | **1 — LLM 분석** | 있으면 편하지만 **없어도 수동 입력으로 100% 대체 가능**. 나중에 얹으면 됨 |
| 병행 | **8 — 인프라** | DB, 인증, 테스트는 다른 Phase 진행하면서 필요할 때 점진적으로 강화 |

### 예상 타임라인

```
         Week 1    Week 2-5     Week 6-7     Week 8-13
           │          │            │             │
Phase 0 ━━┥          │            │             │
Phase 2   │━━━━━━━━━━┥            │             │
Phase 3   │      ━━━━┥            │             │
Phase 4   │          │━━━━━━━━━━━━┥━━━━━━━━━━━━━┥
Phase 5   │          │            │━━━━━━━━━━━━━┥
           │          │            │             │
         Week 14-21     Week 22-24    Week 25-27
           │               │             │
Phase 6 ━━━┥━━━━━━━━━━━━━━━┥             │
Phase 7    │               │━━━━━━━━━━━━━┥
Phase 1    │               │         ━━━━┥
           │               │             │
Phase 8 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  (전 구간 병행)
```

### Priority Tiers

| Tier | Phases | 이유 |
|------|--------|------|
| **Tier 1 — 당장 필요** | 0, 2, 3 | 이것 없이는 도구 자체가 동작하지 않는다 |
| **Tier 2 — 핵심 루프** | 4, 5 | 이미지 생성 → 프록시 편집. 가장 많이 반복하는 작업 구간 |
| **Tier 3 — 프로덕션** | 6, 7 | 여기까지 되면 실제 작품 제작 가능 |
| **Tier 4 — 편의/자동화** | 1 | LLM 시나리오 분석. 편하지만 수동 대체 가능 |
| **Foundation** | 8 | 인프라. 전 구간 병행하며 점진적으로 강화 |

---

## Current Status vs Target (개발 순서 기준)

| Dev Order | Area | Current | Target | Phase |
|-----------|------|---------|--------|-------|
| 1st | 버그/안정성 | 런타임 에러 다수, print 로깅 | 에러 없이 기동, 구조화 로깅 | 0 |
| 2nd | 샷리스트 편집 | 기본 테이블 (버그 있음) | Airtable급 편집 + 엑셀 왕복 | 2 |
| 3rd | 데이터 구조 | 수동 | 컨펌 → 네이밍 컨벤션 자동 생성 | 3 |
| 4th | 이미지 생성 | FLUX 기본만 | t2i + i2i + 이미지 편집 AI + 인페인팅 | 4 |
| 4th | 프롬프트 | 기본 조립 | LoRA + 컨트롤넷 + 캐릭터/환경/스펙 완전 통합 | 4 |
| 5th | 타임라인 | 스켈레톤 UI | 프록시 편집 + 드래그 리사이즈 + EDL 출력 | 5 |
| 6th | DCC 연동 | 없음 | Blender 브릿지 + 플레이블라스트 왕복 | 6 |
| 6th | AI 렌더 | 단일 워크플로우 | 멀티 모델 (WAN, LTX-2, SVI) + 우선순위 큐 | 6 |
| 7th | 후처리 | 없음 | 프레임 보간 + 업스케일 + 포맷 변환 | 7 |
| 8th | 시나리오 분석 | 없음 | LLM 자동 분석 → 캐릭터/샷/배경 분리 (편의) | 1 |
| 병행 | 인프라 | 인메모리, 무인증 | DB + JWT + 워커 장애 복구 | 8 |
| 병행 | 테스트 | 없음 | Unit + Integration 테스트 | 8 |

---

## Technical Decisions Log

| 결정 | 선택 | 이유 | 대안 |
|------|------|------|------|
| Backend | FastAPI | 비동기 지원, Pydantic 통합, 빠른 개발 | Django (과도), Flask (비동기 약함) |
| Frontend | React + Vite | 생태계, 성능, 컴포넌트 재사용 | Vue (가능), Svelte (생태계 작음) |
| 실시간 통신 | WebSocket | 양방향, 저지연 | SSE (단방향), 폴링 (비효율) |
| 데이터 | JSON → SQLite → PostgreSQL | 점진적 마이그레이션 | MongoDB (스키마리스 장점 있으나 관계 약함) |
| LLM | OpenAI API + Ollama | 품질(OpenAI) + 로컬 독립성(Ollama) | Anthropic API |
| 렌더팜 | Master-Worker (WebSocket) | 단순, 확장 가능 | Celery+Redis (오버엔지니어링) |
| DCC 브릿지 | REST API + 파일 교환 | 범용성, DCC 불문 | 직접 플러그인 (DCC별 개발 필요) |
| 영상 처리 | ffmpeg | 범용, 검증됨 | moviepy (래퍼, 유연성 부족) |

---

## Key Risks

| Risk | Impact | Mitigation |
|------|--------|------------|
| LLM 시나리오 분석 품질 편차 | 초기 데이터 품질 저하 | 프롬프트 템플릿 정교화 + 수동 편집 항상 가능 |
| i2v 모델 품질 불안정 | 최종 렌더 품질 편차 | 첫 이미지 퀄리티 확보에 집중 + 멀티 모델 A/B 테스트 |
| VRAM 부족 | 대형 모델(LTX-2) 실행 불가 | VRAM 기반 스케줄링 + 모델별 최소 요구량 명시 |
| 단일 JSON 파일 손상 | 프로젝트 데이터 소실 | Phase 8에서 DB 마이그레이션 + 백업 |
| DCC 연동 복잡도 | 개발 기간 초과 | 파일 기반 교환 우선, 직접 연동은 후순위 |
| ComfyUI API 변경 | 워크플로우 호환성 깨짐 | 워크플로우 버전 관리 + 어댑터 패턴 |

---

## Appendix: Workflow Type Reference

| Workflow | Use Case | VRAM | Phase |
|----------|----------|------|-------|
| FLUX (t2i) | 첫 이미지 생성 | 12-16GB | Phase 4 |
| FLUX (i2i) | 이미지 리파인 | 12-16GB | Phase 4 |
| QwenImageEdit | 이미지 부분 편집 | 8-12GB | Phase 4 |
| ControlNet | 포즈/깊이 조건 생성 | 14-18GB | Phase 4 |
| WAN-Animate | 범용 i2v | 16-24GB | Phase 6 |
| LTX-2 | 고품질 i2v | 24-48GB | Phase 6 |
| SVI | 최신 i2v | 16-24GB | Phase 6 |
| TeleStyle | 스타일 트랜스퍼 | 12-16GB | Phase 6 |
| FFLF | 고품질 영상 | 20-24GB+ | Phase 6 |
| RIFE | 프레임 보간 | 4-8GB | Phase 7 |
| Real-ESRGAN | 업스케일 | 4-8GB | Phase 7 |

---

*This roadmap is a living document. Update as requirements evolve.*
*Last updated: 2026-02-04*
